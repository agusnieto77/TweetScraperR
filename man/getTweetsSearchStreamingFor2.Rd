% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/getTweetsSearchStreamingFor2.R
\name{getTweetsSearchStreamingFor2}
\alias{getTweetsSearchStreamingFor2}
\title{Get Iterative Tweets in Streaming II}
\usage{
getTweetsSearchStreamingFor2(
  iterations,
  search,
  n_tweets,
  sleep = 15,
  xuser = Sys.getenv("USER"),
  xpass = Sys.getenv("PASS"),
  dir = getwd(),
  system = "unix",
  kill_system = FALSE,
  sleep_time = 300,
  max_retries = 3,
  backoff_factor = 2,
  consolidate_data = TRUE,
  cleanup_individual = FALSE,
  verbose = TRUE,
  progress_file = NULL,
  resume_from = 1
)
}
\arguments{
\item{iterations}{Número de iteraciones a realizar}

\item{search}{Término de búsqueda para los tweets}

\item{n_tweets}{Número de tweets a recolectar en cada iteración}

\item{sleep}{Tiempo de espera para la carga de tweets. Por defecto este valor es de 15 segundos.}

\item{xuser}{Nombre de usuario de Twitter para autenticación. Por defecto es el valor de la variable de entorno del sistema USER.}

\item{xpass}{Contraseña de Twitter para autenticación. Por defecto es el valor de la variable de entorno del sistema PASS.}

\item{dir}{Directorio donde se guardarán los tweets}

\item{system}{Sistema operativo ('windows', 'unix', 'macOS')}

\item{kill_system}{Booleano que indica si se debe cerrar el navegador después de cada iteración (por defecto: FALSE)}

\item{sleep_time}{Tiempo de espera entre iteraciones en segundos. Por defecto este valor es de 300 segundos.}

\item{max_retries}{Número máximo de reintentos por iteración (por defecto: 3)}

\item{backoff_factor}{Factor de backoff exponencial entre reintentos (por defecto: 2)}

\item{consolidate_data}{Booleano para unificar todos los datos en un único archivo al final (por defecto: TRUE)}

\item{cleanup_individual}{Booleano para eliminar archivos individuales después de unificar (por defecto: FALSE)}

\item{verbose}{Booleano para mostrar mensajes detallados (por defecto: TRUE)}

\item{progress_file}{Archivo para guardar el progreso de la recolección (por defecto: NULL)}

\item{resume_from}{Iteración desde la cual resumir la recolección (por defecto: 1)}
}
\value{
Lista con estadísticas de la recolección y ruta del archivo unificado (si aplica)
}
\description{
\if{html}{\out{<a href="https://lifecycle.r-lib.org/articles/stages.html#experimental" target="_blank">}}\if{html}{\out{<img src="https://lifecycle.r-lib.org/articles/figures/lifecycle-experimental.svg" alt="[Experimental]">}}\if{html}{\out{</a>}}

Esta función recolecta tweets de forma iterativa utilizando la función optimizada
getTweetsSearchStreaming2, con manejo robusto de errores, seguimiento de progreso,
unificación de datos y gestión eficiente de recursos del sistema.
Optimización realizada con asistencia de Claude Sonnet 4 (Anthropic).
}
\examples{
\dontrun{
# Uso básico
result <- getTweetsSearchStreamingFor2(
  iterations = 5,
  search = "Milei",
  n_tweets = 100,
  dir = "./data/tweets"
)

# Uso avanzado con opciones de recuperación
result <- getTweetsSearchStreamingFor2(
  iterations = 10,
  search = "#datascience",
  n_tweets = 200,
  dir = "./data/tweets",
  system = "unix",
  kill_system = TRUE,
  sleep_time = 600,
  max_retries = 5,
  consolidate_data = TRUE,
  cleanup_individual = TRUE,
  progress_file = "./progress.rds",
  verbose = TRUE
)

# Resumir recolección desde iteración específica
result <- getTweetsSearchStreamingFor2(
  iterations = 10,
  search = "#RStats",
  n_tweets = 150,
  dir = "./data/tweets",
  resume_from = 6,
  progress_file = "./progress.rds"
)
}

}
\references{
Puedes encontrar más información sobre el paquete TweetScrapeR en:
\url{https://github.com/agusnieto77/TweetScraperR}

Función optimizada con asistencia de Claude Sonnet 4 (Anthropic, 2025).
Optimizaciones incluyen: manejo robusto de errores, seguimiento de progreso,
unificación de datos, y gestión eficiente de recursos del sistema.
}
